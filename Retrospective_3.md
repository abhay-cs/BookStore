Retrospective
One of the biggest struggles we’ve had as a group throughout the past two iterations is our testing. Looking back at our feedback for our submissions we have really under performed there, and can be improved a lot. In addition to that we as a group have also acknowledged and known about how our tests did not fully meet our standards for good quality tests. For example, our unit tests for iteration 1 received feedback about how they were not modularized which was a simple fix from our end and the test itself ended up having an error when the markers tried to run it. Then for our second iteration our tests didn’t fully cover everything needed, as a marker reported “the application logic layer is only marginally covered.” and not automated. So looking back on the iterations a lot of problems were because we wouldn’t leave enough time to write really solid tests since the main pieces of the code would be finished really late and leave a very limited amount of time to write up the tests. After discussing some strategies we could implement in iteration 3, we have planned to have a strict “cut off” time for our code where we will wrap up and finish all the features that we have started working on. But will still drop a feature iif we know for certain that we don’t have enough time to complete it since you shouldn’t push an unfinished feature and it’s best to use the time resourcefully. Now by this point once that is done we will begin writing tests to cover everything we have until that point. Since we have created a foundation of tests we can now continue to implement additional features and add more tests to our project if we would like to while having reassurance that we have a version of our project that is still ready to submit. This will also help us be more organized as well since we are carefully writing all the tests for our code comfortably and even making adjustments to our code when tests we thought would pass are failing, rather than chaotically trying to write as many tests as we can with the submission time approaching rapidly and not realizing how much or little we are covering in some areas. This also indirectly helps us with another problem we’ve had and have touched on a bit about previously which is our organization and time management so I think this solution will be very beneficial for us in this final iteration.




A list of some things that we have come up with that we will be satisfied with about our tests on this iteration final iteration is if:
1. The test suite is automated because it makes tests easier and quicker to run, especially when there are a lot of tests for a big project.
2. 80% of the application logic layer is covered including all complex logic with using Mockito
3. The integration tests cover our architectural seams
4. All our completed user stories have an acceptance test
5. All of the tests pass